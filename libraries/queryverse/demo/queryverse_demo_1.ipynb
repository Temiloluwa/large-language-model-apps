{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # Defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8k6m3k9a9GO05s8UqGNDAN4siT7FW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1705999819, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=9, total_tokens=18))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo QueryVerse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queryverse.llm import OpenAILLM\n",
    "from queryverse.prompter import SystemPrompter, AssistantPrompter, UserPrompter\n",
    "\n",
    "gpt_client = OpenAILLM(is_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'assistant': 'Translate this phrase to German: Dies ist der Tag, den der Herr gemacht hat.', 'finish_reason': 'stop'}], 'usage': {'completion_tokens': 17, 'prompt_tokens': 44, 'total_tokens': 61}}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = SystemPrompter(\"\"\"\n",
    "        You are a fluent German speaker and great at translating. \n",
    "    \"\"\")\n",
    "\n",
    "user_prompt = UserPrompter(\"\"\"\n",
    "    Translate this word to German: {word}\n",
    "\"\"\")\n",
    "\n",
    "word = \"This is the day that the Lord has made\"\n",
    "temperature = 1\n",
    "stream = False\n",
    "\n",
    "messages = [\n",
    "  system_prompt(), user_prompt(word=word)  \n",
    "]\n",
    "\n",
    "\n",
    "response = gpt_client.prompt(messages=messages, temperature=temperature, stream=stream)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "queryverse-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
